
from bs4 import BeautifulSoup
from urllib import request
import requests



def mkdir(path):
    # 引入模块
    import os

    # 去除首位空格
    path = path.strip()
    # 去除尾部 \ 符号
    path = path.rstrip("\\")

    # 判断路径是否存在
    # 存在     True
    # 不存在   False
    isExists = os.path.exists(path)
    # 判断结果
    if not isExists:
        # 如果不存在则创建目录
        # 创建目录操作函数
        os.makedirs(path)
        return True
    else:
        # 如果目录存在则不创建，并提示目录已存在
        return False

def get_all_downLink(url):
    r = requests.get(url)
    html = r.text
    soup=BeautifulSoup(html, 'html.parser')
    return soup.find_all('a', target="_blank")



def download(url):
    #print('Downloading:',url)
    html = request.urlopen(url).read()
    return html

def crawl_mp3(name, last):

    url = "https://res.wx.qq.com/voice/getvoice?mediaid="
    path = "/python_project/间客/"+str(name[0:3])
    mkdir(path)
    url = url + last
    path = path + "/" + name + ".mp3"
    r = requests.get(url)
    print(path)
    with open(path, "wb") as f:
        f.write(r.content)
    f.close()
    print('ok')


def start_download_url(link_lists):
    for index, item in enumerate(link_lists):
        link = item['href']
        #link = item.split('\t')[1]
        # link = "http://mp.weixin.qq.com/s?__biz=MzIyMjg4NDA1OA==&mid=2247485837&idx=1&sn=d74d7ba47f6ef477d2f11efbbcbc8895&chksm=e827f038df50792efcce67d3ef933cbc483874b36e71f0d843f2274c0fab3799d7c9272ad8bd&scene=21#wechat_redirect"
        html = download(link)
        soup = BeautifulSoup(html, 'lxml')
        # last = soup.find(id='voice_encode_fileid')
        a = soup.find('mpvoice')
        name = a['name']
        last = a['voice_encode_fileid']
        #print(last)
        name = ''.join(name.split('|'))
        name = ''.join(name.split('间客'))
        name = ''.join(name.split())
        #print(name)
        crawl_mp3(name, last)

if __name__ == '__main__':
    url1="https://mp.weixin.qq.com/s/ZSymfyV9WuHgx492sotB-w"
    url2="https://mp.weixin.qq.com/s/_1rRtmoB-n0H-LoOg0yw4Q"
    url3="https://mp.weixin.qq.com/s/Dw-S9pRgPbcKsVyiLxzigA"
    url4="https://mp.weixin.qq.com/s/8ll0a0tphPbn67idAqMJ9A"
    url=[url1,url2,url3,url4]
    for item in url:
        downLink=get_all_downLink(item)
        start_download_url(downLink)
    #get_all_link("https://mp.weixin.qq.com/s/8ll0a0tphPbn67idAqMJ9A")
    #get_all_downLink(url4)

